{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sift in OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lialic/computer_vision/blob/master/Midterm/Sift_in_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-EUxq2T7qG"
      },
      "source": [
        "# Scale-Invariant Feature Transform\n",
        "\n",
        "With the same size of window, it can not detect Keypoint, especially with bigger edges\n",
        "\n",
        "Bất biến với kích cỡ ảnh, dựa vào gradient của pixel, một vùng 8 chiều. Khi tăng cường độ sáng thì gradient ảnh hưởng. \n",
        "\n",
        "Được sử dụng để thay cho LoG khi mà nó hoạt độg như một máy dò phát hiện các đốm màu khách kích cỡ khi thay đổi $\\sigma$.\n",
        "\n",
        "Ở đây $\\sigma$ được dùng như một tham số tỷ lệ, gaussian có sigma thấp cho giá trị cao với góc nhỏ, vì thế sigma cao sẽ phù hợp cho trường hợp này hơn.\n",
        "\n",
        "Tuy nhiên LoG hơi tốn kém, vì thế sử dụng SIFT ở trường hợp này thì sự khác nhau giữa Gaussian và LoG không quá chênh lệch.\n",
        "\n",
        "Cái khác cúa Gaussian là làm mờ hình ảnh với hai sigma khác nhau.\n",
        "\n",
        "# Keypoint Localization \n",
        "Sau khi tìm được các Keypoint thì chúng phải được tinh chỉnh để có kết quả chính xác hơn.\n",
        "\n",
        "Thứ nhất, sử dụng chuỗi Taylor mở rộng không gian tỷ lệ -> Keypoint chính xác hơn\n",
        "\n",
        "Thứ hai, loại bỏ các cạnh (DoG có phản hồi cao với các cạnh) = cách sử dụng ma trận Hessian 2x2 (H) để dự đoán độ cong (giá trị eigen lớn hơn ở các cạnh vì thế nếu eigen lớn hơn một ngưỡng thì điểm đó sẽ bị loại bỏ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OiVBTTZMD1y"
      },
      "source": [
        "# Mount drive and import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCCGpfpTTzp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4782b9c-fe77-49b2-d868-420e17934a28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge9FyyJNf0vQ"
      },
      "source": [
        "!pip install opencv-python==3.4.2.17\n",
        "!pip install opencv-contrib-python==3.4.2.17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUlM9PGjgerl"
      },
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/Data/mnist_png.tar.gz\", \"/content/mnist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utPqcMs2MQ7n"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc5BSRbKQDdH"
      },
      "source": [
        "## Unzip the .tar.gz file and load it into to the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UG-EMzecfcP"
      },
      "source": [
        "## Adding file_name to image_path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdD2t97QOYiZ"
      },
      "source": [
        "path = './mnist/mnist_png/training'\n",
        "\n",
        "image_path = []\n",
        "\n",
        "# Adding all 10 classes picture name into \n",
        "for i in range(10):\n",
        "    dir = os.path.join(path, str(i))\n",
        "    for file in os.listdir(dir):\n",
        "        image_path.append(os.path.join(dir, file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM8HeWrVcnkX"
      },
      "source": [
        "## Auxiliary function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6OjF3W7XuuD"
      },
      "source": [
        "def CalcFeatures(img, th):\n",
        "\n",
        "        '''\n",
        "        Return descriptor which is used to append to the feature list\n",
        "        Args:\n",
        "        img - name of the image file\n",
        "        th - threshhold \n",
        "        '''\n",
        "\n",
        "        sift = cv2.xfeatures2d.SIFT_create(th)\n",
        "        kp, des = sift.detectAndCompute(img, None)\n",
        "        return des\n",
        "def bag_of_features(features, centres, k = 500):\n",
        "        '''\n",
        "        The bag_of_features function assigns the features which are similar\n",
        "        to a specific cluster centre thus forming a Bag of Words approach.  \n",
        "        '''\n",
        "\n",
        "        vec = np.zeros((1,k))\n",
        "        for i in range(features.shape[0]):\n",
        "            feat = features[i]\n",
        "            diff = np.tile(feat, (k,1)) - centres\n",
        "            dist = pow(((pow(diff, 2)).sum(axis = 1)), 0.5)\n",
        "            idx_list = dist.argsort()\n",
        "            idx = idx_list[0]\n",
        "            vec[0][idx] +=1\n",
        "        \n",
        "        return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnS2cggOQ_Ib"
      },
      "source": [
        "def main(thresh):\n",
        "    t0 = time.time()\n",
        "\n",
        "    '''\n",
        "    All the files appended to the image_path list are passed through the\n",
        "    CalcFeatures functions which returns the descriptors which are \n",
        "    appended to the features list and then stacked vertically in the form\n",
        "    of a numpy array.\n",
        "    '''\n",
        "\n",
        "    features = []\n",
        "    for file in image_path:\n",
        "        # Read the file as gray-scale image\n",
        "        img = cv2.imread(file, 0)\n",
        "\n",
        "        img_des = CalcFeatures(img, thresh)\n",
        "        if img_des is not None:\n",
        "            features.append(img_des)\n",
        "\n",
        "    # Stack all the previous collected features into vertical np array  \n",
        "    features = np.vstack(features)\n",
        "\n",
        "    '''\n",
        "    K-Means clustering is then performed on the feature array obtained \n",
        "    from the previous step. The centres obtained after clustering are \n",
        "    further used for bagging of features.\n",
        "    '''\n",
        "\n",
        "    k = 150\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.1)\n",
        "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
        "    compactness, labels, centres = cv2.kmeans(features, k, None, criteria, 10 , flags)\n",
        "\n",
        "    \n",
        "    labels = []\n",
        "    vec = []\n",
        "    for file in image_path:\n",
        "        img = cv2.imread(file, 0)\n",
        "        img_des = CalcFeatures(img, thresh)\n",
        "\n",
        "        if img_des is not None:\n",
        "            img_vec = bag_of_features(img_des, centres, k)\n",
        "            vec.append(img_vec)\n",
        "            labels.append(int(file[27]))\n",
        "\n",
        "    vec = np.vstack(vec)\n",
        "\n",
        "    # Split data for trainning and testing SVM classifier\n",
        "    x_train, x_test, y_train, y_test = train_test_split(vec, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "    clf = SVC()\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    preds = clf.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    conf_mat = confusion_matrix(y_test, preds)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    return accuracy * 100, conf_mat, (t1-t0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ0H0-Z2ZL3r",
        "outputId": "12cdcdd8-3b8d-465c-ce96-359a7a4a62fe"
      },
      "source": [
        "accuracy = []\n",
        "timer = []\n",
        "for i in range(5, 26, 5):\n",
        "    print('\\nCalculating for a threshold of {}'.format(i))\n",
        "    data = main(i)\n",
        "    accuracy.append(data[0])\n",
        "    conf_mat = data[1]\n",
        "    timer.append(data[2])\n",
        "    print('\\nAccuracy = {}\\nTime taken = {} sec\\nConfusion matrix :\\n{}'.format(data[0],data[2],data[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating for a threshold of 5\n",
            "\n",
            "Accuracy = 67.22388059701493\n",
            "Time taken = 828.3164970874786 sec\n",
            "Confusion matrix :\n",
            "[[ 996    6   22   11    3   27   36   12   24   18]\n",
            " [   0 1116   11    4   15    5    3   13    2    9]\n",
            " [  65   12  584   95   74   43   31  166   71   29]\n",
            " [  36    0  151  725   49  122   16   53   29   23]\n",
            " [  10   10   88   32  794   41   25   59   43   82]\n",
            " [  93    7   32   71   39  681   61   51   22   37]\n",
            " [  98   18   47   15   14   44  608   66   49  214]\n",
            " [  22   67  112   37   38   14   43  854   11   14]\n",
            " [  61   10   51   29   44   33   50   11  812   58]\n",
            " [  44    5   35   29   52   67  160   19   73  712]]\n",
            "\n",
            "Calculating for a threshold of 10\n",
            "\n",
            "Accuracy = 76.07675906183368\n",
            "Time taken = 911.0088083744049 sec\n",
            "Confusion matrix :\n",
            "[[1011    5   17    6    0   13   51   23   12   17]\n",
            " [   0 1122    9    1   15    5    6   15    3    2]\n",
            " [  39    7  798   45   24   29   26  149   41   12]\n",
            " [  14    0   81  887   20  106   21   31   34   10]\n",
            " [   7    4   35   17  982   23   16   30   28   42]\n",
            " [  56    6   29   52   26  744   85   42   20   34]\n",
            " [  71   16   17   12   10   57  704   57   39  190]\n",
            " [  16   61   84   18   36   15   33  932    8    9]\n",
            " [  29    8   38   23   41   22   41    9  909   39]\n",
            " [  25    4   30    9   42   44  154   16   41  831]]\n",
            "\n",
            "Calculating for a threshold of 15\n",
            "\n",
            "Accuracy = 77.02345415778251\n",
            "Time taken = 948.5472676753998 sec\n",
            "Confusion matrix :\n",
            "[[1035    3   12    4    2   22   36   25    9    7]\n",
            " [   1 1129   11    0   12    6    3   12    2    2]\n",
            " [  33   14  774   39   32   42   33  141   46   16]\n",
            " [  16    0   51  907    9  107   26   36   31   21]\n",
            " [   2    6   22   15  987   20   19   35   30   48]\n",
            " [  48    5   24   47   15  781   70   49   17   38]\n",
            " [  64   17   22    8   11   61  679   75   17  219]\n",
            " [  16   58   72   16   39   13   40  939   10    9]\n",
            " [  21    9   29   17   36   13   36    8  951   39]\n",
            " [  30    4   19   16   35   60  142   13   28  849]]\n",
            "\n",
            "Calculating for a threshold of 20\n",
            "\n",
            "Accuracy = 77.94456289978679\n",
            "Time taken = 946.7881252765656 sec\n",
            "Confusion matrix :\n",
            "[[1033    4   15    2    2   20   47   17    5   10]\n",
            " [   0 1128   12    1   11    1    7   12    4    2]\n",
            " [  41   11  816   39   29   26   21  126   53    8]\n",
            " [  16    2   58  911   14  100   16   35   36   16]\n",
            " [   4    8   30   13 1002   26   20   31   22   28]\n",
            " [  57    5   29   41   13  751   89   44   17   48]\n",
            " [  92   15   20    5    7   54  702   54   14  210]\n",
            " [  15   54   76   19   27   13   44  946   10    8]\n",
            " [  29   13   27   18   26   16   22   10  959   39]\n",
            " [  27    8   19   15   33   42  117   19   25  891]]\n",
            "\n",
            "Calculating for a threshold of 25\n",
            "\n",
            "Accuracy = 77.74840085287846\n",
            "Time taken = 942.7004234790802 sec\n",
            "Confusion matrix :\n",
            "[[1010    3   14    4    1   23   59   21   11    9]\n",
            " [   0 1129    8    2   11    2    9   13    3    1]\n",
            " [  34   12  824   43   29   33   27  121   38    9]\n",
            " [  13    0   78  922   16   75   20   26   33   21]\n",
            " [   4    4   40   13  978   25   17   30   25   48]\n",
            " [  53    8   36   41   18  760   79   54    9   36]\n",
            " [  86   17   22    3   16   55  703   64   11  196]\n",
            " [  15   56   69    8   33   21   46  949    5   10]\n",
            " [  19    8   33   29   28   15   23    5  969   30]\n",
            " [  24    6   23   18   40   44  123   22   24  872]]\n"
          ]
        }
      ]
    }
  ]
}